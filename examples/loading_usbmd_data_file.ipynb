{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Loading an USBMD data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory to the root of the repository\n",
    "# We do this by moving up until we find the file users.yaml (which is in the\n",
    "# root of the repository)\n",
    "import os\n",
    "\n",
    "while not os.path.exists('users.yaml'):\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the file structure\n",
    "The USBMD data format works with HDF5 files. We can open a USBMD data file using the `h5py` package and have a look at the contents using the print_hdf5_attrs function. You can see that every dataset element contains a corresponding description and unit.\n",
    "\n",
    "> *Tip:*\n",
    "> You can also use the [HDFView](https://www.hdfgroup.org/downloads/hdfview/) tool to view the contents of the USBMD data file without having to run any code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from usbmd.utils.utils import print_hdf5_attrs\n",
    "import cv2\n",
    "\n",
    "# Define path to the data file\n",
    "data_path = r\"data/planewave_heart_l115v_0000.hdf5\"\n",
    "\n",
    "# Open the file and print the contents\n",
    "with h5py.File(data_path, 'r') as f:\n",
    "    print_hdf5_attrs(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the file with the toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from usbmd.data_format.usbmd_data_format import load_usbmd_file\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load the data file and construct a probe and scan object\n",
    "# We will only load the first two frames of the data file\n",
    "data, scan, probe = load_usbmd_file(data_path, frames=[0, 1])\n",
    "\n",
    "# Hack that is needed because the Scan base class does not contain the angles\n",
    "# attribute and the beamformer assumes that it does\n",
    "scan.angles = np.linspace(0, 2, scan.N_tx, endpoint=False)\n",
    "\n",
    "# Print some info about the data\n",
    "print('Data file loaded successfully')\n",
    "print('The data tensor has shape: {}'.format(data.shape))\n",
    "print('The dimensions of the data are (n_frames, n_transmits, n_elements, '\n",
    "      'n_axial_samples, n_rf_iq_channels)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beamforming the data\n",
    "Now we would like to beamform the data to generate an image. For this we need to load a config file that contains the beamforming parameters. We can load a config using the `load_config_from_yaml` function. Once we have a config we create the beamformer using get_beamformer with the scan and probe class that we got from the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from usbmd.pytorch_ultrasound.layers.beamformers import get_beamformer\n",
    "from usbmd.utils.config import load_config_from_yaml\n",
    "from usbmd.utils.config_validation import check_config\n",
    "\n",
    "# Load the config file\n",
    "config_path = Path('configs', 'config_usbmd_rf.yaml')\n",
    "config = load_config_from_yaml(config_path)\n",
    "\n",
    "# Check the config file for errors\n",
    "check_config(config)\n",
    "\n",
    "# Create the beamformer\n",
    "beamformer = get_beamformer(probe=probe, scan=scan, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from usbmd.processing import envelope_detect, rf2iq, log_compress\n",
    "\n",
    "# Transform the data to IQ data\n",
    "iq_data = rf2iq(data,\n",
    "                fs=scan.fs,\n",
    "                fc=scan.fc,\n",
    "                bandwidth=probe.bandwidth,\n",
    "                separate_channels=False)\n",
    "\n",
    "# Turn the data into a torch tensor\n",
    "iq_data = torch.from_numpy(iq_data)\n",
    "\n",
    "# Beamform the data\n",
    "beamformer_output = beamformer(iq_data)\n",
    "\n",
    "image = beamformer_output['beamformed'].numpy()[0, :, :, 0]\n",
    "\n",
    "image = np.abs(image)\n",
    "\n",
    "image = image/image.max()\n",
    "image = log_compress(image)\n",
    "\n",
    "print(f'Image shape: {image.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the image\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.imshow(image,\n",
    "          cmap='gray',\n",
    "          extent=[scan.xlims[0], scan.xlims[1], scan.zlims[1], scan.zlims[0]])\n",
    "\n",
    "ax.set_xlabel('Lateral distance [m]')\n",
    "ax.set_ylabel('Depth [m]')\n",
    "\n",
    "# Turn the figure black\n",
    "ax.set_facecolor((0, 0, 0))\n",
    "fig.patch.set_facecolor((0, 0, 0))\n",
    "\n",
    "# Turn the ticks white\n",
    "ax.tick_params(axis='both', colors='white')\n",
    "\n",
    "# Turn the labels white\n",
    "ax.xaxis.label.set_color('white')\n",
    "ax.yaxis.label.set_color('white')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
