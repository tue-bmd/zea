{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PICMUS beamforming with usbmd toolbox\n",
    "The PICMUS dataset is one of the most widely used ultrasound datasets in the research community. The dataset is available at https://www.creatis.insa-lyon.fr/Challenge/IEEE_IUS_2016/.\n",
    "In this tutorial we show you how to use the dataset with the usbmd toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First make sure you have installed the usbmd toolbox using our [installation instructions](../../README.md). Next, we need to prepare the PICMUS dataset for use with the toolbox. After download, convert the dataset to the usbmd format using the following command:\n",
    "```bash\n",
    "python usbmd/data/convert/picmus.py --source <path_to_downloaded_dataset> --output <path_to_output_dir>\n",
    "```\n",
    "\n",
    "Also make sure to then correctly setup your data paths by running\n",
    " ```bash\n",
    " python usbmd/datapaths.py\n",
    " ```\n",
    "All paths in the repository are relative to the root of the repository you set using the previous step.\n",
    "\n",
    "Then add the (relative) location of your converted PICMUS dataset to `./configs/config_picmus_rf.yaml`. In this tutorial, we assume the following relative path:\n",
    "\n",
    "```yaml\n",
    "# ./configs/config_picmus_rf.yaml\n",
    "data:\n",
    "  dataset_folder: \"USBMD_datasets/PICMUS/database/simulation/contrast_speckle/contrast_speckle_simu_dataset_rf\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to the root of the project by moving up in the\n",
    "# directory tree until the file '.gitignore' is found.\n",
    "import os\n",
    "\n",
    "while not os.path.exists('.gitignore'):\n",
    "    os.chdir('..')\n",
    "\n",
    "# Set to True to run the notebook quickly for testing purposes This is done\n",
    "# automatically in 'tests/test_run_notebooks.py'\n",
    "quick_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# injected parameters\n",
    "quick_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 15:01:22.706241: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-08 15:01:22.767501: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-08 15:01:22.767548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-08 15:01:22.769211: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-08 15:01:22.777773: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-08 15:01:23.935802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from usbmd.ui import DataLoaderUI\n",
    "from usbmd.setup_usbmd import setup\n",
    "from usbmd.ops import Pipeline, Downsample, Demodulate, Normalize, EnvelopeDetect, LogCompress, DelayAndSum, TOFCorrection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PICMUS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments - resolution distortion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF beamforming\n",
    "Let's load the RF data and beamform it. First have a look at the most easy way to do it using our `DataloaderUI` class and setup config functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36musbmd\u001b[0m\u001b[0m: Using config file: \u001b[33m./configs/config_picmus_rf.yaml\u001b[0m\n",
      "\u001b[1m\u001b[38;5;36musbmd\u001b[0m\u001b[0m: Git branch and commit: feature/ops_beamformer=4a4c0f572bfe68775df01006b17043eb7702e3d1\n",
      "\u001b[1m\u001b[38;5;36musbmd\u001b[0m\u001b[0m: \u001b[38;5;214mWARNING\u001b[0m output path `output` does not exist, please update your \u001b[33musers.yaml\u001b[0m file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------GPU settings-------------------\n",
      "     memory\n",
      "GPU        \n",
      "0      9640\n",
      "1     11008\n",
      "2     11008\n",
      "3     11008\n",
      "4     11008\n",
      "5     11008\n",
      "6     11008\n",
      "7     11008\n",
      "Selected GPU 1 with Free Memory: 11008.00 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ultrasound-toolbox/usbmd/datapaths.py:101: UnknownHostnameWarning: Unknown hostname bmdserver3 for user devcontainer15 and no default data_root found.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiding GPUs [0, 2, 3, 4, 5, 6, 7] from the system.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Loads config, sets data paths and initializes gpu if available\n",
    "config = setup(config_path=\"./configs/config_picmus_rf.yaml\")\n",
    "\n",
    "# Override config settings\n",
    "config.plot.save = False\n",
    "config.plot.headless = True\n",
    "\n",
    "# data paths\n",
    "config.data.dataset_folder = \"USBMD_datasets/PICMUS/database/simulation/contrast_speckle/contrast_speckle_simu_dataset_rf\"\n",
    "config.data.file_path = \"contrast_speckle_simu_dataset_rf.hdf5\"\n",
    "config.plot.headless = False # you can set to False to see the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36musbmd\u001b[0m\u001b[0m: Dataset was validated on \u001b[32mJanuary 18, 2024\u001b[0m\n",
      "\u001b[1m\u001b[38;5;36musbmd\u001b[0m\u001b[0m: Remove \u001b[33m/mnt/z/Ultrasound-BMd/data/USBMD_datasets/PICMUS/database/simulation/contrast_speckle/contrast_speckle_simu_dataset_rf/validated.flag\u001b[0m if you want to redo validation.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Cannot load backend 'QtAgg' which requires the 'qt' interactive framework, as 'headless' is currently running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quick_mode:\n\u001b[0;32m----> 2\u001b[0m     ui \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoaderUI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     image \u001b[38;5;241m=\u001b[39m ui\u001b[38;5;241m.\u001b[39mrun(plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/ultrasound-toolbox/usbmd/ui.py:115\u001b[0m, in \u001b[0;36mDataLoaderUI.__init__\u001b[0;34m(self, config, verbose)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheadless \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mplot\u001b[38;5;241m.\u001b[39mheadless\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_for_display()\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_backend_for_notebooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mfile_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    118\u001b[0m     window_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mfile_name\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m/ultrasound-toolbox/usbmd/ui.py:170\u001b[0m, in \u001b[0;36mDataLoaderUI.set_backend_for_notebooks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set backend to QtAgg if running in notebook\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m running_in_notebook() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheadless:\n\u001b[0;32m--> 170\u001b[0m     \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQtAgg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py:1255\u001b[0m, in \u001b[0;36muse\u001b[0;34m(backend, force)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;66;03m# we need this import check here to re-raise if the\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;66;03m# user does not have the libraries to support their\u001b[39;00m\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;66;03m# chosen backend installed.\u001b[39;00m\n\u001b[0;32m-> 1255\u001b[0m         \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   1257\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m force:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py:423\u001b[0m, in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    420\u001b[0m     current_framework \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39m_get_running_interactive_framework()\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (current_framework \u001b[38;5;129;01mand\u001b[39;00m required_framework\n\u001b[1;32m    422\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m current_framework \u001b[38;5;241m!=\u001b[39m required_framework):\n\u001b[0;32m--> 423\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    424\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load backend \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m which requires the \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m interactive \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframework, as \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is currently running\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    426\u001b[0m                 newbackend, required_framework, current_framework))\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# Load the new_figure_manager() and show() functions from the backend.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Classically, backends can directly export these functions.  This should\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# keep working for backcompat.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m new_figure_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_figure_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mImportError\u001b[0m: Cannot load backend 'QtAgg' which requires the 'qt' interactive framework, as 'headless' is currently running"
     ]
    }
   ],
   "source": [
    "if not quick_mode:\n",
    "    ui = DataLoaderUI(config)\n",
    "    image = ui.run(plot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IQ beamforming\n",
    "We can also load the IQ data and beamform it.\n",
    "\n",
    "No need to reload a new config (although you can use `./configs/config_picmus_iq.yaml`).\n",
    "We can simply set n_ch to 2 and change the data file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.scan.n_ch = 2\n",
    "config.data.dataset_folder = \"USBMD_datasets/PICMUS/database/simulation/contrast_speckle/contrast_speckle_simu_dataset_iq\"\n",
    "config.data.file_path = \"contrast_speckle_simu_dataset_iq.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not quick_mode:\n",
    "    ui = DataLoaderUI(config)\n",
    "    image = ui.run(plot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IQ beamforming, but reading RF data\n",
    "For this, we need a more manual approach. Let's first load the RF data, but now in `raw_data` format. After that we can manually convert it to IQ data and beamform it. We can now either again use the `Process` class, or we can construct our own custom processing `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "\n",
    "config.data.dataset_folder = \"USBMD_datasets/PICMUS/database/simulation/contrast_speckle/contrast_speckle_simu_dataset_rf\"\n",
    "config.data.file_path = \"contrast_speckle_simu_dataset_rf.hdf5\"\n",
    "config.scan.n_ch = 1\n",
    "config.scan.downsample = 4\n",
    "\n",
    "if not quick_mode:\n",
    "    ui = DataLoaderUI(config)\n",
    "    # >> load data\n",
    "    raw_data_rf = ui.get_data()\n",
    "    # select transmits to use\n",
    "    raw_data_rf = raw_data_rf[ui.scan.selected_transmits]\n",
    "\n",
    "    # >> convert RF to IQ\n",
    "    print(f\"RF data has shape {raw_data_rf.shape}\")\n",
    "\n",
    "    # >> process data\n",
    "    # Let's make a pipeline to process the data\n",
    "    demodulate_func = Demodulate(fs=ui.scan.fs, fc=ui.scan.fc, ops=config.ml_library)\n",
    "\n",
    "    raw_data_rf = demodulate_func.prepare_tensor(raw_data_rf)\n",
    "    raw_data_iq = demodulate_func.process(raw_data_rf)\n",
    "\n",
    "    print(f\"IQ data has shape {raw_data_iq.shape}\")\n",
    "\n",
    "    # now we have IQ data, the number of channels is 2\n",
    "    ui.scan.n_ch = 2\n",
    "    # >> beamform data\n",
    "    pipeline = Pipeline([\n",
    "        TOFCorrection(),  # raw_data -> aligned_data\n",
    "        DelayAndSum(),  # aligned_data -> beamformed_data\n",
    "        EnvelopeDetect(),  # beamformed_data -> envelope_data\n",
    "        Downsample(),  # envelope_data -> envelope_data\n",
    "        Normalize(),  # envelope_data -> envelope_data\n",
    "        LogCompress(),  # envelope_data -> image\n",
    "    ],\n",
    "        ops=config.ml_library,\n",
    "        batch_dim=False,\n",
    "    )\n",
    "    pipeline.set_params(config, ui.scan, ui.probe)\n",
    "    pipeline.initialize()\n",
    "\n",
    "    image = pipeline.process(raw_data_iq)\n",
    "    ui.dtype = \"image\"\n",
    "    ui.data = image\n",
    "\n",
    "    # >> plot image\n",
    "    ui.plot(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulations - resolution distortion\n",
    "For fun, let's look at another PICMUS dataset as an example. This is a simulated dataset, generating a bunch of scatterers. Often we can use it to look at the resolution of our ultrasound pipeline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF beamforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "config.data.dataset_folder = \"USBMD_datasets/PICMUS/database/simulation/resolution_distorsion/resolution_distorsion_simu_dataset_rf\"\n",
    "config.data.file_path = \"resolution_distorsion_simu_dataset_rf.hdf5\"\n",
    "config.scan.n_ch = 1\n",
    "\n",
    "if not quick_mode:\n",
    "    ui = DataLoaderUI(config)\n",
    "    image = ui.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality is not really impressive. But wait, in the config we specified the number of transmits (in this case number of plane wave angels) to be 7. The total in the dataset is 75. Let's see how it looks using all of them. \n",
    "This can take a bit longer... Reduce the number of transmits or use cpu instead of gpu if you run into any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not quick_mode:\n",
    "    config.scan.selected_transmits = 30\n",
    "    ui = DataLoaderUI(config)\n",
    "    image = ui.run(plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf26_usbmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
