{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bf4a2d4",
   "metadata": {},
   "source": [
    "# Using `zea.Models`: UNet Example for Ultrasound Image Inpainting\n",
    "\n",
    "In this notebook, we demonstrate how to use the `zea.Models` interface with a popular deep learning architecture: the UNet. We'll use a pretrained UNet to inpaint missing regions in ultrasound images, and visualize the results. This workflow can be adapted for other tasks and models in the `zea` toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947a6cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a391c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Using backend 'torch'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749846265.545158    4624 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749846265.551585    4624 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749846265.568635    4624 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749846265.568656    4624 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749846265.568658    4624 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749846265.568660    4624 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras import ops\n",
    "\n",
    "from zea import init_device, log\n",
    "from zea.backend.tensorflow.dataloader import make_dataloader\n",
    "from zea.models.unet import UNet\n",
    "from zea.models.lpips import LPIPS\n",
    "from zea.agent.masks import random_uniform_lines\n",
    "from zea.visualize import plot_image_grid, set_mpl_style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bab632",
   "metadata": {},
   "source": [
    "We will work with the GPU if available, and initialize using `init_device` to pick the best available device. Also, (optionally), we will set the matplotlib style for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0a6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = init_device(verbose=False)\n",
    "set_mpl_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b593ea4",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We load a small batch from the CAMUS validation dataset hosted on Hugging Face Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50167c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Using pregenerated dataset info file: \u001b[33m/home/devcontainer15/.cache/zea/huggingface/datasets/datasets--zeahub--camus-sample/snapshots/617cf91a1267b5ffbcfafe9bebf0813c7cee8493/val/dataset_info.yaml\u001b[0m ...\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: ...for reading file paths in \u001b[33m/home/devcontainer15/.cache/zea/huggingface/datasets/datasets--zeahub--camus-sample/snapshots/617cf91a1267b5ffbcfafe9bebf0813c7cee8493/val\u001b[0m\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Dataset was validated on \u001b[32mJune 13, 2025\u001b[0m\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Remove \u001b[33m/home/devcontainer15/.cache/zea/huggingface/datasets/datasets--zeahub--camus-sample/snapshots/617cf91a1267b5ffbcfafe9bebf0813c7cee8493/val/validated.flag\u001b[0m if you want to redo validation.\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: \u001b[38;5;214mWARNING\u001b[0m H5Generator: Not all files have the same shape. This can lead to issues when resizing images later....\n",
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: H5Generator: Shuffled data.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Bad StatusOr access: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/data/util/structure.py:105\u001b[39m, in \u001b[36mnormalize_element\u001b[39m\u001b[34m(element, element_signature)\u001b[39m\n\u001b[32m    104\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     spec = \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    107\u001b[39m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[32m    108\u001b[39m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/data/util/structure.py:514\u001b[39m, in \u001b[36mtype_spec_from_value\u001b[39m\u001b[34m(element, use_fallback)\u001b[39m\n\u001b[32m    511\u001b[39m     logging.vlog(\n\u001b[32m    512\u001b[39m         \u001b[32m3\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (\u001b[38;5;28mtype\u001b[39m(element).\u001b[34m__name__\u001b[39m, e))\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    515\u001b[39m     element,\n\u001b[32m    516\u001b[39m     \u001b[38;5;28mtype\u001b[39m(element).\u001b[34m__name__\u001b[39m))\n",
      "\u001b[31mTypeError\u001b[39m: Could not build a `TypeSpec` for 0 with type int",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.device(device):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     val_dataset = \u001b[43mmake_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhf://zeahub/camus-sample/val\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/image\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_imgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresize_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimage_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalization_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     batch = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(val_dataset))\n\u001b[32m     17\u001b[39m     batch = ops.clip(batch, -\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ultrasound-toolbox/zea/backend/tensorflow/dataloader.py:288\u001b[39m, in \u001b[36mmake_dataloader\u001b[39m\u001b[34m(file_paths, batch_size, key, n_frames, shuffle, return_filename, limit_n_samples, limit_n_frames, seed, drop_remainder, resize_type, resize_axes, resize_kwargs, image_size, image_range, normalization_range, dataset_repetitions, cache, additional_axes_iter, sort_files, overlapping_blocks, augmentation, assert_image_range, clip_image_range, initial_frame_axis, insert_frame_axis, frame_index_stride, frame_axis, validate, prefetch, shard_index, num_shards, wrap_in_keras, **kwargs)\u001b[39m\n\u001b[32m    266\u001b[39m image_extractor = H5GeneratorTF(\n\u001b[32m    267\u001b[39m     file_paths,\n\u001b[32m    268\u001b[39m     key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    284\u001b[39m     **kwargs,\n\u001b[32m    285\u001b[39m )\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# Create dataset\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m dataset = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_extractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_signature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_extractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_signature\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[38;5;66;03m# Assert cardinality\u001b[39;00m\n\u001b[32m    293\u001b[39m dataset = dataset.apply(tf.data.experimental.assert_cardinality(\u001b[38;5;28mlen\u001b[39m(image_extractor)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/util/deprecation.py:588\u001b[39m, in \u001b[36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    580\u001b[39m         _PRINTED_WARNING[(func, arg_name)] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    581\u001b[39m       _log_deprecation(\n\u001b[32m    582\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is deprecated and will \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    583\u001b[39m           \u001b[33m'\u001b[39m\u001b[33mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    586\u001b[39m           \u001b[33m'\u001b[39m\u001b[33min a future version\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m % date),\n\u001b[32m    587\u001b[39m           instructions)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:969\u001b[39m, in \u001b[36mDatasetV2.from_generator\u001b[39m\u001b[34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[39m\n\u001b[32m    965\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[32m    966\u001b[39m \u001b[38;5;66;03m# from_generator_op -> dataset_ops).\u001b[39;00m\n\u001b[32m    967\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_generator_op\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_generator_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43moutput_signature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py:323\u001b[39m, in \u001b[36m_from_generator\u001b[39m\u001b[34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;66;03m# A single-element dataset that, each time it is evaluated, contains a\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[38;5;66;03m# freshly-generated and unique (for the returned dataset) int64\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# ID that will be used to identify the appropriate Python state, which\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[38;5;66;03m# is encapsulated in `generator_state`, and captured in\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# `get_iterator_id_map_fn`.\u001b[39;00m\n\u001b[32m    322\u001b[39m dummy = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m id_dataset = \u001b[43mdataset_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# A dataset that contains all of the elements generated by a\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# single iterator created from `generator`, identified by the\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;66;03m# iterator ID contained in `id_dataset`. Lifting the iteration\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# into a flat_map here enables multiple repetitions and/or nested\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# versions of the returned dataset to be created, because it forces\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# the generation of a new ID for each version.\u001b[39;00m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m id_dataset.flat_map(flat_map_fn, name=name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:741\u001b[39m, in \u001b[36mDatasetV2.from_tensors\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[32m    738\u001b[39m \u001b[38;5;66;03m# from_tensors_op -> dataset_ops).\u001b[39;00m\n\u001b[32m    739\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_tensors_op\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensors_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/data/ops/from_tensors_op.py:23\u001b[39m, in \u001b[36m_from_tensors\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_tensors\u001b[39m(tensors, name):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/data/ops/from_tensors_op.py:31\u001b[39m, in \u001b[36m_TensorDataset.__init__\u001b[39m\u001b[34m(self, element, name)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     30\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"See `tf.data.Dataset.from_tensors` for details.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m   element = \u001b[43mstructure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m   \u001b[38;5;28mself\u001b[39m._structure = structure.type_spec_from_value(element)\n\u001b[32m     33\u001b[39m   \u001b[38;5;28mself\u001b[39m._tensors = structure.to_tensor_list(\u001b[38;5;28mself\u001b[39m._structure, element)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/data/util/structure.py:110\u001b[39m, in \u001b[36mnormalize_element\u001b[39m\u001b[34m(element, element_signature)\u001b[39m\n\u001b[32m    105\u001b[39m     spec = type_spec_from_value(t, use_fallback=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    107\u001b[39m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[32m    108\u001b[39m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[32m    109\u001b[39m   normalized_components.append(\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m       \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    112\u001b[39m   \u001b[38;5;66;03m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[32m    113\u001b[39m   \u001b[38;5;66;03m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[32m    114\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m spec.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mDatasetSpec\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/profiler/trace.py:183\u001b[39m, in \u001b[36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, **trace_kwargs):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:736\u001b[39m, in \u001b[36mconvert_to_tensor\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[32m    735\u001b[39m preferred_dtype = preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[39m\n\u001b[32m    225\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    226\u001b[39m           _add_error_prefix(\n\u001b[32m    227\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for type \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m               \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret.dtype.base_dtype.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    231\u001b[39m               name=name))\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m   ret = \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m    237\u001b[39m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[39m, in \u001b[36m_constant_tensor_conversion_function\u001b[39m\u001b[34m(v, dtype, name, as_ref)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[32m     28\u001b[39m _ = as_ref\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[39m, in \u001b[36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[39m, in \u001b[36mconstant\u001b[39m\u001b[34m(value, dtype, shape, name)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m\"\u001b[39m, v1=[])\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstant\u001b[39m(\n\u001b[32m    179\u001b[39m     value, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, shape=\u001b[38;5;28;01mNone\u001b[39;00m, name=\u001b[33m\"\u001b[39m\u001b[33mConst\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m ) -> Union[ops.Operation, ops._EagerTensorBase]:\n\u001b[32m    181\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[32m    182\u001b[39m \n\u001b[32m    183\u001b[39m \u001b[33;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[39m, in \u001b[36m_constant_impl\u001b[39m\u001b[34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[39m\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m trace.Trace(\u001b[33m\"\u001b[39m\u001b[33mtf.constant\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    288\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m const_tensor = ops._create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    292\u001b[39m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[32m    293\u001b[39m )\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[39m, in \u001b[36m_constant_eager_impl\u001b[39m\u001b[34m(ctx, value, dtype, shape, verify_shape)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_constant_eager_impl\u001b[39m(\n\u001b[32m    298\u001b[39m     ctx, value, dtype, shape, verify_shape\n\u001b[32m    299\u001b[39m ) -> ops._EagerTensorBase:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m   t = \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/framework/constant_op.py:107\u001b[39m, in \u001b[36mconvert_to_eager_tensor\u001b[39m\u001b[34m(value, ctx, dtype)\u001b[39m\n\u001b[32m    105\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m    106\u001b[39m     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/tensorflow/python/eager/context.py:726\u001b[39m, in \u001b[36mContext.ensure_initialized\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    722\u001b[39m   pywrap_tfe.TFE_ContextOptionsSetRunEagerOpAsFunction(opts, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    723\u001b[39m   pywrap_tfe.TFE_ContextOptionsSetJitCompileRewrite(\n\u001b[32m    724\u001b[39m       opts, \u001b[38;5;28mself\u001b[39m._jit_compile_rewrite\n\u001b[32m    725\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m   context_handle = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_NewContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    728\u001b[39m   pywrap_tfe.TFE_DeleteContextOptions(opts)\n",
      "\u001b[31mRuntimeError\u001b[39m: Bad StatusOr access: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory"
     ]
    }
   ],
   "source": [
    "n_imgs = 8\n",
    "import torch\n",
    "with torch.device(device):\n",
    "\n",
    "    val_dataset = make_dataloader(\n",
    "        \"hf://zeahub/camus-sample/val\",\n",
    "        key=\"data/image\",\n",
    "        batch_size=n_imgs,\n",
    "        shuffle=True,\n",
    "        image_size=[128, 128],\n",
    "        resize_type=\"resize\",\n",
    "        image_range=[-60, 0],\n",
    "        normalization_range=[-1, 1],\n",
    "        seed=42,\n",
    "    )\n",
    "    batch = next(iter(val_dataset))\n",
    "    batch = ops.clip(batch, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8236a9f1",
   "metadata": {},
   "source": [
    "## Load UNet Model\n",
    "\n",
    "We use a pretrained UNet model from `zea` for inpainting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538e4e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;5;36mzea\u001b[0m\u001b[0m: Available built-in zea presets for UNet: ['unet-echonet-inpainter']\n"
     ]
    }
   ],
   "source": [
    "presets = list(UNet.presets.keys())\n",
    "log.info(f\"Available built-in zea presets for UNet: {presets}\")\n",
    "\n",
    "model = UNet.from_preset(\"unet-echonet-inpainter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0481c9",
   "metadata": {},
   "source": [
    "## Simulate Missing Data\n",
    "\n",
    "We simulate missing data by masking out random columns in each image (e.g., 75% missing). This is a common scenario in cognitive ultrasound where some scanlines may be missing (i.e. not acquired) or corrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fe5aefe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ones() received an invalid combination of arguments - got (device=str, dtype=torch.dtype, size=Tensor, ), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m n_columns = \u001b[32m128\u001b[39m\u001b[38;5;66;03m#batch.shape[2]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m mask = \u001b[43mrandom_uniform_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_columns\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_imgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m corrupted = batch * ops.cast(mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, :, \u001b[38;5;28;01mNone\u001b[39;00m], batch.dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ultrasound-toolbox/zea/agent/masks.py:84\u001b[39m, in \u001b[36mrandom_uniform_lines\u001b[39m\u001b[34m(n_actions, n_possible_actions, n_masks, seed, dtype)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Will generate a mask with random lines.\u001b[39;00m\n\u001b[32m     69\u001b[39m \n\u001b[32m     70\u001b[39m \u001b[33;03mGuarantees precisely n_actions.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \u001b[33;03m            Needs to be converted to image size.\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     83\u001b[39m masks = keras.random.uniform([n_masks, n_possible_actions], seed=seed, dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m masks = \u001b[43mhard_straight_through\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ops.cast(masks, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/ultrasound-toolbox/zea/agent/gumbel.py:102\u001b[39m, in \u001b[36mhard_straight_through\u001b[39m\u001b[34m(khot_orig, k, n_value_dims)\u001b[39m\n\u001b[32m     91\u001b[39m scatter_indices = ops.stack(\n\u001b[32m     92\u001b[39m     [\n\u001b[32m     93\u001b[39m         ops.repeat(ops.arange(ops.shape(khot)[\u001b[32m0\u001b[39m]), k),\n\u001b[32m   (...)\u001b[39m\u001b[32m     96\u001b[39m     axis=-\u001b[32m1\u001b[39m,\n\u001b[32m     97\u001b[39m )\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Create the hard k-hot tensor\u001b[39;00m\n\u001b[32m    100\u001b[39m khot_hard = ops.scatter(\n\u001b[32m    101\u001b[39m     scatter_indices,\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfloat32\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[32m    103\u001b[39m     ops.shape(khot),\n\u001b[32m    104\u001b[39m )\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Straight-through estimator\u001b[39;00m\n\u001b[32m    107\u001b[39m out = khot_hard - ops.stop_gradient(khot) + khot\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/keras/src/ops/numpy.py:6728\u001b[39m, in \u001b[36mones\u001b[39m\u001b[34m(shape, dtype)\u001b[39m\n\u001b[32m   6717\u001b[39m \u001b[38;5;129m@keras_export\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mkeras.ops.ones\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkeras.ops.numpy.ones\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   6718\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mones\u001b[39m(shape, dtype=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   6719\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a new tensor of given shape and type, filled with ones.\u001b[39;00m\n\u001b[32m   6720\u001b[39m \n\u001b[32m   6721\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   6726\u001b[39m \u001b[33;03m        Tensor of ones with the given shape and dtype.\u001b[39;00m\n\u001b[32m   6727\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6728\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/keras/src/backend/torch/numpy.py:228\u001b[39m, in \u001b[36mones\u001b[39m\u001b[34m(shape, dtype)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m    227\u001b[39m     shape = (shape,)\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: ones() received an invalid combination of arguments - got (device=str, dtype=torch.dtype, size=Tensor, ), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "n_columns = 128#batch.shape[2]\n",
    "mask = random_uniform_lines(n_columns // 4, n_columns, n_imgs)\n",
    "corrupted = batch * ops.cast(mask[:, None, :, None], batch.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425a18e",
   "metadata": {},
   "source": [
    "## Inpaint with UNet\n",
    "\n",
    "We use the UNet to inpaint the missing regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db6bd7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a random batch with the correct shape and device\n",
    "random_batch = torch.randn((n_imgs, n_columns, n_columns, 1), device=device)\n",
    "inpainted = model(random_batch)\n",
    "inpainted = ops.clip(inpainted, -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c2595",
   "metadata": {},
   "source": [
    "## Evaluate Perceptual Similarity\n",
    "\n",
    "We use the LPIPS metric to evaluate perceptual similarity between the ground truth and inpainted images. For more detailed example of this metric, see [this notebook](lpips_example.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cefc069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpips = LPIPS.from_preset(\"lpips\")\n",
    "lpips_scores = lpips([inpainted, inpainted])\n",
    "lpips_scores = ops.convert_to_numpy(lpips_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f0011",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We plot the ground truth, corrupted, inpainted, and error images. The LPIPS score is shown on each inpainted image. Note that this model was trained on the EchoNet-Dynamic dataset, whereas we are testing now on the CAMUS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d488b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m error = ops.abs(\u001b[43mbatch\u001b[49m - inpainted)\n\u001b[32m      2\u001b[39m imgs = ops.concatenate([batch, corrupted, inpainted, error], axis=\u001b[32m0\u001b[39m)\n\u001b[32m      3\u001b[39m imgs = ops.convert_to_numpy(imgs)\n",
      "\u001b[31mNameError\u001b[39m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "error = ops.abs(batch - inpainted)\n",
    "imgs = ops.concatenate([batch, corrupted, inpainted, error], axis=0)\n",
    "imgs = ops.convert_to_numpy(imgs)\n",
    "\n",
    "cmaps = [\"gray\"] * (3 * n_imgs) + [\"viridis\"] * n_imgs\n",
    "\n",
    "fig, _ = plot_image_grid(\n",
    "    imgs,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    ncols=n_imgs,\n",
    "    remove_axis=False,\n",
    "    cmap=cmaps,\n",
    "    figsize=(n_imgs * 2, 6),\n",
    ")\n",
    "\n",
    "titles = [\"Ground Truth\", \"Corrupted\", \"Inpainted\", \"Error\"]\n",
    "for i, ax in enumerate(fig.axes[: len(titles) * n_imgs]):\n",
    "    if i % n_imgs == 0:\n",
    "        ax.set_ylabel(titles[i // n_imgs])\n",
    "\n",
    "# Show LPIPS score on each inpainted image\n",
    "for ax, lpips_score in zip(fig.axes[n_imgs * 2 : 3 * n_imgs], lpips_scores):\n",
    "    ax.text(\n",
    "        0.95,\n",
    "        0.95,\n",
    "        f\"LPIPS: {float(lpips_score):.4f}\",\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=8,\n",
    "        color=\"yellow\",\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07263d70",
   "metadata": {},
   "source": [
    "You can try other UNet presets or experiment with different masking strategies to explore the capabilities of `zea.Models`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
