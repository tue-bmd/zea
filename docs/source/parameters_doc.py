"""Automatically generate comments in YAML config files based on parameter descriptions.

Also generates a reStructuredText (RST) file for sphinx documentation.
"""

# noqa: E501

import os
import re
import sys
from pathlib import Path

from schema import And, Optional, Or, Schema

from zea import log
from zea.config.parameters import PARAMETER_DESCRIPTIONS

AUTOGEN_HEADER_TEMPLATE = "# {filename} - comments were autogenerated from PARAMETER_DESCRIPTIONS in zea/config/parameters.py\n"
AUTOGEN_HEADER_KEYWORD = "autogenerated"
PROBES_YAML = "probes.yaml"


# Determine if we are running from the docs directory or project root
def get_project_paths():
    """Get the project paths for configs and parameters.rst based on the current working directory."""
    cwd = Path.cwd().resolve()
    # If we're in docs or docs/source, adjust accordingly
    if "docs" in cwd.parts:
        configs_dir = cwd.parent / "configs"
        rst_path = cwd / "source" / "parameters.rst"
    else:
        configs_dir = cwd / "configs"
        rst_path = cwd / "docs" / "source" / "parameters.rst"

    # Ensure the configs directory exists
    if not configs_dir.exists():
        raise FileNotFoundError(f"Configs directory does not exist: {configs_dir}")
    # Ensure the rst path is valid
    if not rst_path.parent.exists():
        raise FileNotFoundError(f"RST path does not exist: {rst_path.parent}")

    return configs_dir, rst_path


CONFIGS_DIRNAME, PARAMETERS_RST_PATH = get_project_paths()


def flatten_dict_keys(d, prefix=""):
    """Recursively flatten nested dict keys into dot notation, ignoring 'description' keys."""
    keys = set()
    for k, v in d.items():
        if k == "description":
            continue
        full = f"{prefix}.{k}" if prefix else k
        if isinstance(v, dict):
            keys |= flatten_dict_keys(v, full)
        else:
            keys.add(full)
    return keys


def flatten_schema_keys(schema, prefix=""):
    """Recursively flatten schema keys into dot notation, handling Optional/And/Or."""
    keys = set()
    if isinstance(schema, Schema):
        schema = schema.schema
    if isinstance(schema, dict):
        for k, v in schema.items():
            if isinstance(k, Optional):
                key = k.key
            else:
                key = k
            full = f"{prefix}.{key}" if prefix else str(key)
            if isinstance(v, And):
                if hasattr(v, "_validators") and v._validators:
                    last = v._validators[-1]
                    keys |= flatten_schema_keys(last, full)
                else:
                    keys.add(full)
            elif isinstance(v, Or):
                if hasattr(v, "_options"):
                    for opt in v._options:
                        keys |= flatten_schema_keys(opt, full)
                else:
                    keys.add(full)
            elif isinstance(v, (Schema, dict)):
                keys |= flatten_schema_keys(v, full)
            else:
                keys.add(full)
    return keys


def wrap_string_as_comment(input_string, indent_level=0, max_line_length=100, indent_size=2):
    """Limit the length of lines in a string and adds a comment prefix."""
    if isinstance(input_string, dict):
        input_string = input_string.get("description", "-")
    if not isinstance(input_string, str):
        input_string = str(input_string)
    indent = " " * (indent_level * indent_size)
    prefix = indent + "# "
    prefix_length = len(prefix)
    if max_line_length <= prefix_length:
        raise ValueError("max_line_length must be greater than the length of the prefix")
    words = input_string.split()
    result_lines = []
    current_line = prefix
    for word in words:
        if len(current_line) + len(word) + 1 > max_line_length:
            result_lines.append(current_line)
            current_line = prefix + word
        else:
            if current_line != prefix:
                current_line += " "
            current_line += word
    if current_line:
        result_lines.append(current_line)
    return "\n".join(result_lines) + "\n"


def process_yaml_content(lines, descriptions, indent_size=2):
    """Process YAML content line by line and add comments."""
    modified_lines = []
    current_keys = []
    data_found = False
    plot_found = False
    for line in lines:
        if line.strip().startswith("#"):
            continue
        if re.match(r"^\s*\w+\s*:", line):
            indent_level = len(re.match(r"^\s*", line).group(0)) // indent_size
            current_keys = current_keys[:indent_level]
            key = line.split(":")[0].strip()
            current_keys.append(key)
            if key == "data" and indent_level == 0:
                data_found = True
            if key == "plot" and indent_level == 0:
                plot_found = True
            # Special handling: skip comments for operation entries inside pipeline.operations
            if (
                len(current_keys) >= 3
                and current_keys[0] == "pipeline"
                and current_keys[1] == "operations"
            ):
                # Do not add comments for keys inside operations list
                modified_lines.append(line)
                continue
            description = descriptions
            try:
                for key in current_keys:
                    description = description[key]
            except Exception:
                description = "-"
            comment_lines = wrap_string_as_comment(
                description, indent_level, max_line_length=80, indent_size=indent_size
            )
            # Only add comment if it's not just "# -"
            if comment_lines.strip() != "# -":
                modified_lines.append(comment_lines)
            modified_lines.append(line)
        else:
            modified_lines.append(line)
    if data_found and plot_found:
        return modified_lines
    else:
        print("data and/or plot key not found. Not adding comments.")
        return lines


def add_comments_to_yaml(file_path, descriptions):
    """Adds comments to a YAML file based on a descriptions dictionary."""
    header = AUTOGEN_HEADER_TEMPLATE.format(filename=file_path.name)
    with open(file_path, "r", encoding="utf-8") as file:
        content = file.readlines()
    if content and content[0].startswith("#") and AUTOGEN_HEADER_KEYWORD in content[0]:
        content = content[1:]
    modified_content = process_yaml_content(content, descriptions)
    modified_content = [header] + modified_content
    with open(file_path, "w", encoding="utf-8") as file:
        file.writelines(modified_content)


def check_parameter_descriptions(descriptions, schema):
    """Check for missing or extra parameter descriptions (ignoring 'description' keys).
    Returns (missing, extra) as sets.
    """
    rst_keys = flatten_dict_keys(descriptions)
    schema_keys = flatten_schema_keys(schema)
    missing = sorted(schema_keys - rst_keys)
    extra = sorted(rst_keys - schema_keys)
    return missing, extra


def dict_to_rst_table(param_dict):
    """Convert a nested dictionary to a reStructuredText (RST) table."""
    lines = []
    lines.append(".. list-table::")
    lines.append("   :header-rows: 1")
    lines.append("   :widths: 20 80\n")
    lines.append("   * - **Parameter**")
    lines.append("     - **Description**")

    def recurse(d, prefix=""):
        for k in sorted(d):
            if k == "description":
                continue
            v = d[k]
            param_name = f"{prefix}.{k}" if prefix else k
            if isinstance(v, dict):
                desc = v.get("description", "")
                lines.append(f"   * - ``{param_name}``\n     - {desc}")
                recurse(v, param_name)
            else:
                lines.append(f"   * - ``{param_name}``\n     - {v}")

    recurse(param_dict)
    return "\n".join(lines)


def create_parameters_rst(param_dict, rst_path=PARAMETERS_RST_PATH):
    """Generate a reStructuredText (RST) file from the parameter dictionary."""
    intro = """.. THIS FILE WAS AUTOGENERATED USING docs/parameters_doc.py. DO NOT EDIT MANUALLY.

.. _parameters:

Parameters
===========

This page provides a comprehensive overview of all configuration parameters available in zea.
These parameters are used in the YAML config files to control data loading, preprocessing, model settings, scan parameters, and more.

.. note::
  You can use these configs to, for instance, initialize :doc:`zea.Models <models>` or :doc:`zea.Pipeline <pipeline>`.

Configs are written in YAML format and can be loaded, edited, and saved using the zea API.

-------------------------------
How to Load and Save a Config
-------------------------------

Here is a minimal example of how to load and save a config file using zea:

.. code-block:: python

   from zea import Config
   from zea.config.validation import check_config

   # Load a config from file
   config = Config.from_yaml("configs/config_picmus_rf.yaml")

   # We can check if the config has valid parameters (zea compliance)
   config = check_config(config)

   # Access parameters
   print(config.scan.sampling_frequency)
   config.scan.sampling_frequency = 8e6

   # Save the config back to file
   config.to_yaml("configs/config_picmus_rf_modified.yaml")

-------------------------------
Parameter List
-------------------------------

Below is a hierarchical list of all configuration parameters, grouped by section.
Descriptions are shown for each parameter.

.. contents::
   :local:
   :depth: 2

-------------------------------
Parameters Reference
-------------------------------
"""
    table = dict_to_rst_table(param_dict)
    with open(rst_path, "w", encoding="utf-8") as f:
        f.write(intro)
        f.write("\n")
        f.write(table)
        f.write("\n")
    log.info(f"Generated {rst_path} from PARAMETER_DESCRIPTIONS.")


def update_configs(descriptions, configs_dir=CONFIGS_DIRNAME):
    """Update YAML config files with comments based on parameter descriptions."""
    config_dir = Path(configs_dir)
    yaml_files = [f for f in os.listdir(config_dir) if f.endswith(".yaml") or f.endswith(".yml")]
    yaml_files = [f for f in yaml_files if f != PROBES_YAML]
    for file_name in yaml_files:
        log.info(f"Adding comments to {config_dir / file_name}")
        add_comments_to_yaml(config_dir / file_name, descriptions)


if __name__ == "__main__":
    from zea.config.validation import config_schema

    # 1. Check parameter descriptions
    missing, extra = check_parameter_descriptions(PARAMETER_DESCRIPTIONS, config_schema)
    if missing:
        log.warning(
            "The following config parameters are missing descriptions in PARAMETER_DESCRIPTIONS:"
        )
        for k in missing:
            print(f"- {k}")
    if extra:
        log.warning(
            "The following parameters are described in PARAMETER_DESCRIPTIONS but do not exist in the config schema:"
        )
        for k in extra:
            print(f"- {k}")
    if missing or extra:
        log.error("Parameter description check failed. Please fix the above issues.")
        sys.exit(1)
    else:
        log.info("All config parameters are documented in PARAMETER_DESCRIPTIONS.")

    # 2. Generate parameters.rst
    create_parameters_rst(PARAMETER_DESCRIPTIONS)

    # 3. Update YAML configs with comments
    update_configs(PARAMETER_DESCRIPTIONS)
